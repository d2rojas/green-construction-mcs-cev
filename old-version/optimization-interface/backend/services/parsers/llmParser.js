const { OPENAI_CONFIG } = require('../../config/openai');

class LLMParser {
  constructor(openaiClient) {
    this.openai = openaiClient;
  }

  /**
   * Parse scenario configuration from natural language
   * @param {string} userInput - User's natural language input
   * @param {Object} currentContext - Current conversation context
   * @returns {Object} Parsed scenario configuration
   */
  async parseScenarioConfiguration(userInput, currentContext = {}) {
    const prompt = this.buildScenarioPrompt(userInput, currentContext);
    
    try {
      const response = await this.openai.chat.completions.create({
        model: OPENAI_CONFIG.model,
        messages: [
          {
            role: 'system',
            content: prompt
          },
          {
            role: 'user',
            content: userInput
          }
        ],
        max_tokens: 500,
        temperature: 0.1, // Low temperature for consistent parsing
        response_format: { type: "json_object" }
      });

      const parsedData = JSON.parse(response.choices[0].message.content);
      return this.validateScenarioData(parsedData);
      
    } catch (error) {
      console.error('Error parsing scenario configuration:', error);
      throw new Error('Failed to parse scenario configuration');
    }
  }

  /**
   * Parse model parameters from natural language
   * @param {string} userInput - User's natural language input
   * @param {Object} currentContext - Current conversation context
   * @returns {Object} Parsed model parameters
   */
  async parseModelParameters(userInput, currentContext = {}) {
    const prompt = this.buildParametersPrompt(userInput, currentContext);
    
    try {
      const response = await this.openai.chat.completions.create({
        model: OPENAI_CONFIG.model,
        messages: [
          {
            role: 'system',
            content: prompt
          },
          {
            role: 'user',
            content: userInput
          }
        ],
        max_tokens: 800,
        temperature: 0.1,
        response_format: { type: "json_object" }
      });

      const parsedData = JSON.parse(response.choices[0].message.content);
      return this.validateParametersData(parsedData);
      
    } catch (error) {
      console.error('Error parsing model parameters:', error);
      throw new Error('Failed to parse model parameters');
    }
  }

  /**
   * Build prompt for scenario configuration parsing
   */
  buildScenarioPrompt(userInput, context) {
    return `You are an expert parser for MCS-CEV optimization scenarios. Your task is to extract scenario configuration parameters from natural language input.

CURRENT CONTEXT:
${JSON.stringify(context, null, 2)}

USER INPUT: "${userInput}"

EXTRACT the following parameters and return ONLY a JSON object with this exact structure:

{
  "numMCS": <number between 1-10>,
  "numCEV": <number between 1-20>,
  "numNodes": <number between 2-20>,
  "is24Hours": <boolean>,
  "scenarioName": "<auto-generated name>",
  "confidence": <number 0-1>,
  "missingInfo": ["list of missing information"],
  "suggestions": ["list of suggestions"]
}

RULES:
1. numMCS: Number of Mobile Charging Stations (1-10)
2. numCEV: Number of Construction Electric Vehicles (1-20)
3. numNodes: Total locations including grid node and construction sites (2-20)
4. is24Hours: true for 24-hour simulation, false for standard
5. scenarioName: Auto-generate like "1MCS-2CEV-3nodes-24hours"
6. If information is missing, set confidence < 0.8 and list missing info
7. Provide helpful suggestions for missing information

EXAMPLES:
- "I need 2 excavators at 3 sites" → {"numMCS": 1, "numCEV": 2, "numNodes": 4, "is24Hours": true, ...}
- "3 vehicles working 8 hours" → {"numCEV": 3, "is24Hours": false, ...}

Return ONLY the JSON object, no other text.`;
  }

  /**
   * Build prompt for model parameters parsing
   */
  buildParametersPrompt(userInput, context) {
    return `You are an expert parser for MCS-CEV optimization model parameters. Extract technical parameters from natural language input.

CURRENT CONTEXT:
${JSON.stringify(context, null, 2)}

USER INPUT: "${userInput}"

EXTRACT the following parameters and return ONLY a JSON object with this exact structure:

{
  "eta_ch_dch": <number 0-1>,
  "MCS_max": <number in kWh>,
  "MCS_min": <number in kWh>,
  "MCS_ini": <number in kWh>,
  "CH_MCS": <number in kW>,
  "DCH_MCS": <number in kW>,
  "DCH_MCS_plug": <number in kW>,
  "C_MCS_plug": <integer>,
  "k_trv": <number in kWh/mile>,
  "delta_T": <number in hours>,
  "rho_miss": <number>,
  "confidence": <number 0-1>,
  "missingInfo": ["list of missing information"],
  "suggestions": ["list of suggestions"]
}

DEFAULT VALUES (use if not specified):
- eta_ch_dch: 0.95
- MCS_max: 1000.0
- MCS_min: 100.0
- MCS_ini: 500.0
- CH_MCS: 50.0
- DCH_MCS: 50.0
- DCH_MCS_plug: 50.0
- C_MCS_plug: 4
- k_trv: 1.0
- delta_T: 0.5
- rho_miss: 0.6

RULES:
1. Use default values if not specified
2. Validate ranges (efficiency 0-1, capacities positive, etc.)
3. If user mentions specific values, use those instead of defaults
4. Provide confidence score based on completeness
5. List any missing critical information

Return ONLY the JSON object, no other text.`;
  }

  /**
   * Validate scenario configuration data
   */
  validateScenarioData(data) {
    const errors = [];
    
    // Validate ranges
    if (data.numMCS < 1 || data.numMCS > 10) {
      errors.push('numMCS must be between 1 and 10');
    }
    if (data.numCEV < 1 || data.numCEV > 20) {
      errors.push('numCEV must be between 1 and 20');
    }
    if (data.numNodes < 2 || data.numNodes > 20) {
      errors.push('numNodes must be between 2 and 20');
    }
    
    // Validate logical consistency
    if (data.numNodes < data.numCEV) {
      errors.push('Number of nodes should be >= number of CEVs');
    }
    
    if (errors.length > 0) {
      data.errors = errors;
      data.confidence = Math.max(0, data.confidence - 0.3);
    }
    
    return data;
  }

  /**
   * Validate model parameters data
   */
  validateParametersData(data) {
    const errors = [];
    
    // Validate ranges
    if (data.eta_ch_dch < 0 || data.eta_ch_dch > 1) {
      errors.push('eta_ch_dch must be between 0 and 1');
    }
    if (data.MCS_max <= 0) {
      errors.push('MCS_max must be positive');
    }
    if (data.MCS_min <= 0) {
      errors.push('MCS_min must be positive');
    }
    if (data.MCS_ini <= 0) {
      errors.push('MCS_ini must be positive');
    }
    
    // Validate logical consistency
    if (data.MCS_min >= data.MCS_max) {
      errors.push('MCS_min must be less than MCS_max');
    }
    if (data.MCS_ini < data.MCS_min || data.MCS_ini > data.MCS_max) {
      errors.push('MCS_ini must be between MCS_min and MCS_max');
    }
    
    if (errors.length > 0) {
      data.errors = errors;
      data.confidence = Math.max(0, data.confidence - 0.3);
    }
    
    return data;
  }

  /**
   * Parse complete conversation to extract all parameters
   * @param {Array} conversationHistory - Full conversation history
   * @param {Object} currentFormData - Current form data
   * @returns {Object} Complete parsed configuration
   */
  async parseCompleteConfiguration(conversationHistory, currentFormData = {}) {
    const completeConfig = {
      scenario: currentFormData.scenario || {},
      parameters: currentFormData.parameters || {},
      evData: currentFormData.evData || [],
      locations: currentFormData.locations || [],
      timeData: currentFormData.timeData || [],
      distanceMatrix: currentFormData.distanceMatrix || [],
      travelTimeMatrix: currentFormData.travelTimeMatrix || [],
      workData: currentFormData.workData || []
    };

    // Parse each step based on conversation
    for (const message of conversationHistory) {
      if (message.role === 'user') {
        // Try to parse scenario configuration
        try {
          const scenarioData = await this.parseScenarioConfiguration(message.content, completeConfig);
          if (scenarioData.confidence > 0.7) {
            completeConfig.scenario = { ...completeConfig.scenario, ...scenarioData };
          }
        } catch (error) {
          console.log('Could not parse as scenario config:', error.message);
        }

        // Try to parse model parameters
        try {
          const paramData = await this.parseModelParameters(message.content, completeConfig);
          if (paramData.confidence > 0.7) {
            completeConfig.parameters = { ...completeConfig.parameters, ...paramData };
          }
        } catch (error) {
          console.log('Could not parse as model parameters:', error.message);
        }
      }
    }

    return completeConfig;
  }
}

module.exports = LLMParser;
